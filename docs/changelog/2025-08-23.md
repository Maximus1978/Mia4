# Changelog — 2025-08-23

## GPU Enablement & Initial Perf

**Статус:** GPU offload активирован (llama_supports_gpu_offload() = True) после обновления / корректной сборки. Выполнены smoke и scaling прогоны. Полная выгрузка слоёв пока не превосходит оптимизированный CPU.

### Что сделано

- Подтверждена работоспособность CUDA сборки `llama-cpp-python==0.3.16` (SM89). Offload включается, лог фиксирует GPU буферы.
- Добавлены и выполнены скрипты:
  - `scripts/perf_gpu_smoke.py` — короткий прогон (64 токена) для n_gpu_layers: 0,6,12,auto.
  - Ручной свип по GPU слоям → JSON отчёты `reports/perf_gpu_layers{0,6,12,auto}.json` и агрегат `perf_gpu_smoke.json`.
- Расширен раздел GPU Smoke / Scaling в `docs/ТЗ/Perf.md` (таблица метрик, наблюдения, гипотезы).
- Обновлены задачи в `.instructions.md`: отмечены выполненными 10.3 (GPU подготовка) и 10.4 (Scaling); детализирован 10.5 (Long Context) с подзадачами по фиксу скрипта, измерениям и flash attention.
- Добавлена новая задача: приведение `scripts/perf_long_context.py` к PEP8 (4 пробела), гарантированная запись `reports/perf_long_context.json`.
- Первый успешный запуск long-context (512) дал консольный JSON (файл ещё не сохраняется — зафиксировано как технический долг в 10.5).

### Наблюдения (Short Context GPU vs CPU)

| Mode | load_ms (пример) | tokens_per_s | Примечание |
|------|------------------|--------------|------------|
| CPU tuned (n_threads=8, n_batch=256) | ~2340 ms | ~6.69 | Лучший свип |
| GPU 25% (6 слоёв) | ~4.3–4.4 s | ~4.1 | Часть слоёв на GPU |
| GPU 50% (12 слоёв) | ~5.2–5.3 s | ~4.2 | Лёгкое улучшение vs 25% |
| GPU 100% (auto) | ~10.6 s | ~3.4–3.5 | flash_attn=0; высокая загрузка |

Вывод: текущая сборка без flash attention и/или оптимальных CUDA путей. CPU остаётся быстрее для 20B Q4_K_M при 64 токенах.

### Long Context (предварительно)

Первичный (не сохранён в файл) прогон 512 токенов показал ~3.3–3.4 tokens/s при разных n_gpu_layers (0/6/12/auto — разница минимальна), что отражает деградацию производительности при удлинении вывода и отсутствие ускоряющих GPU kernel (flash_attn=0). Будет повторено после фикса скрипта.

### Причины текущего отставания GPU

1. Отсутствие Flash Attention (логи: `flash_attn=0`).
2. Большой выделенный контекст (n_ctx=32768) увеличивает накладные расходы.
3. Возможно неоптимальные параметры n_batch / scheduler на GPU пути.
4. Потенциально не включены некоторые CUTLASS/MMQ оптимизации.

### Следующие шаги (актуализировано в инструкциях)

1. Привести `perf_long_context.py` к чистому PEP8, добавить гарантированную запись JSON.
2. Прогнать 512 токенов CPU vs разные GPU offload уровни → сохранить `reports/perf_long_context.json` и внести таблицу в Perf.md.
3. Оценить деградацию (сравнение tps 64 vs 512, latency рост p50/p95).
4. Пересобрать llama-cpp с flash attention и повторить ключевые прогоны.
5. Сформировать сводку оптимальных режимов (10.6) и обновить README Performance.
6. Реализовать aggregate `perf_probe.py` и подготовить CI smoke (10.7).

### Как улучшает систему

- Даёт количественную базу (CPU vs GPU) для целевых оптимизаций.
- Фиксация задач по long-context и flash attention исключает расползание технического долга.
- Прозрачность прогресса (JSON отчёты + таблицы) повышает наблюдаемость и воспроизводимость.

### Риски / Технический долг

- Отсутствие сохранённого long-context отчёта тормозит анализ деградации.
- Возможная необходимость обновить/пересобрать зависимости для включения flash attention.
- Пока нет автоматизированного aggregate измерения → ручной анализ.

### Интеграция

Все изменения согласованы с текущим спринтом (Steps 10.3–10.5). Дополнительные задачи отражены в `.instructions.md` без расширения скоупа сверх согласованного плана.

---
